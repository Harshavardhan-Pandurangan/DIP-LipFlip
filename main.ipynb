{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LipFlip - DIP Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/harshavardhan/Documents/DIP/DIP-LipFlip/main.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harshavardhan/Documents/DIP/DIP-LipFlip/main.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harshavardhan/Documents/DIP/DIP-LipFlip/main.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/harshavardhan/Documents/DIP/DIP-LipFlip/main.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harshavardhan/Documents/DIP/DIP-LipFlip/main.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mLaplacianBlending\u001b[39;00m \u001b[39mimport\u001b[39;00m LaplacianBlending\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harshavardhan/Documents/DIP/DIP-LipFlip/main.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mImageTools\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageTools\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from classes.LaplacianBlending import LaplacianBlending\n",
    "from classes.ImageTools import ImageTools\n",
    "from classes.DetectionTools import DetectionTools\n",
    "from classes.temp import ColorBalanceMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calling Laplacian Blend\n",
    "def LaplacianBlend(l, r, m):\n",
    "    lb = LaplacianBlending(l, r, m, 20)  # Adjust the last integer to adjust the number of pyramid levels\n",
    "    return lb.blend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "# Scale size\n",
    "scaleSize = (400, 225)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('images/1.jpg')\n",
    "img2 = cv2.imread('images/2.jpg')\n",
    "\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "scaleSize = (640, 480)\n",
    "\n",
    "orig, match, tMatrix = None, None, None\n",
    "IT = ImageTools()\n",
    "foundGoodTransform = False\n",
    "possibleTransform = False\n",
    "\n",
    "while not foundGoodTransform:\n",
    "    orig = cv2.resize(img1, scaleSize)\n",
    "    match = cv2.resize(img2, scaleSize)\n",
    "\n",
    "    useKeypoints = True\n",
    "    possibleTransform = IT.find_gain_transform(orig, match, tMatrix, useKeypoints)\n",
    "\n",
    "    if not possibleTransform:\n",
    "        print(\"No transform found. Trying again...\")\n",
    "        break\n",
    "    else:\n",
    "        foundGoodTransform = True\n",
    "\n",
    "    img2 = img2.astype(np.float32)\n",
    "    new_img2 = np.zeros_like(img2)\n",
    "    IT.apply_gain_transform(img2, new_img2, tMatrix)\n",
    "\n",
    "# Show the images\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(orig)\n",
    "plt.title(\"Image 1\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(match)\n",
    "plt.title(\"Image 2\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(new_img2.astype(np.uint8))  # Convert back to uint8 for displaying\n",
    "plt.title(\"Image 2 after transform\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('images/1.jpg')\n",
    "img2 = cv2.imread('images/2.jpg')\n",
    "\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "scaleSize = (640, 480)\n",
    "\n",
    "matcher = ColorBalanceMatcher()\n",
    "\n",
    "matched_image = matcher.match_color_balance(img1, img2)\n",
    "\n",
    "# Show the images\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img1)\n",
    "plt.title(\"Image 1\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img2)\n",
    "plt.title(\"Image 2\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(matched_image.astype(np.uint8))  # Convert back to uint8 for displaying\n",
    "plt.title(\"Image 2 after transform\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting lip flip session...\")\n",
    "\n",
    "d1 = DetectionTools()\n",
    "d2 = DetectionTools()\n",
    "frame1, frame2 = None, None\n",
    "frame1_temp, frame2_temp = None, None\n",
    "blend_range = 6\n",
    "t = 0\n",
    "\n",
    "while True:\n",
    "    t = cv2.getTickCount()\n",
    "\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    frame1 = cv2.resize(frame1, scaleSize)\n",
    "    frame2 = cv2.resize(frame2, scaleSize)\n",
    "\n",
    "    # Apply the gain matching transform to the second frame\n",
    "    frame2 = IT.applyGainTransform(frame2, tMatrix)\n",
    "    frame2.copyTo(frame2_temp)\n",
    "    frame1.copyTo(frame1_temp)\n",
    "\n",
    "    d1.findLipRegion(frame1)\n",
    "    d2.findLipRegion(frame2)\n",
    "\n",
    "    if not d1.mouthROI.empty() and not d2.mouthROI.empty():\n",
    "        cols1 = d1.mouthROI.shape[1]\n",
    "        cols2 = d2.mouthROI.shape[1]\n",
    "\n",
    "        scaledMouth1 = cv2.resize(d1.mouthROI, (cols2, d1.mouthROI.shape[0]))\n",
    "        scaledMouth2 = cv2.resize(d2.mouthROI, (cols1, d2.mouthROI.shape[0]))\n",
    "\n",
    "        if d1.mouthLoc[1] + scaledMouth2.shape[0] <= frame1.shape[0] and d1.mouthLoc[0] + scaledMouth2.shape[1] <= frame1.shape[1]:\n",
    "            scaledMouth2.copyTo(frame1[d1.mouthLoc[1]:d1.mouthLoc[1] + scaledMouth2.shape[0], d1.mouthLoc[0]:d1.mouthLoc[0] + scaledMouth2.shape[1]])\n",
    "\n",
    "            l8u_1 = frame1\n",
    "            r8u_1 = frame1_temp\n",
    "\n",
    "            l_1 = l8u_1.astype(np.float32) / 255.0\n",
    "            r_1 = r8u_1.astype(np.float32) / 255.0\n",
    "            m_1 = np.zeros(l_1.shape, dtype=np.float32)\n",
    "\n",
    "            mouthCenter1 = (d1.mouthLoc[0] + 0.5 * scaledMouth2.shape[1], d1.mouthLoc[1] + 0.5 * scaledMouth2.shape[0])\n",
    "            mouthAxis1 = (scaledMouth2.shape[1] * 0.5 - blend_range, scaledMouth2.shape[0] * 0.5 - blend_range)\n",
    "\n",
    "            cv2.ellipse(m_1, (int(mouthCenter1[0]), int(mouthCenter1[1])), (int(mouthAxis1[0]), int(mouthAxis1[1])), 0, 0, 360, 1, -1)\n",
    "            blend_1 = LaplacianBlend(l_1, r_1, m_1)\n",
    "\n",
    "            if DEBUG:\n",
    "                cv2.rectangle(blend_1, (d1.rectMouth[0], d1.rectMouth[1]), (d1.rectMouth[0] + d1.rectMouth[2], d1.rectMouth[1] + d1.rectMouth[3]), (0, 255, 0), 1)\n",
    "                cv2.rectangle(blend_1, (d1.rectMouthCascade[0], d1.rectMouthCascade[1]), (d1.rectMouthCascade[0] + d1.rectMouthCascade[2], d1.rectMouthCascade[1] + d1.rectMouthCascade[3]), (0, 0, 255), 1)\n",
    "\n",
    "            cv2.imshow(Window1, (blend_1 * 255).astype(np.uint8))\n",
    "\n",
    "        if d2.mouthLoc[1] + scaledMouth1.shape[0] <= frame2.shape[0] and d2.mouthLoc[0] + scaledMouth1.shape[1] <= frame2.shape[1]:\n",
    "\n",
    "            scaledMouth1.copyTo(frame2[d2.mouthLoc[1]:d2.mouthLoc[1] + scaledMouth1.shape[0], d2.mouthLoc[0]:d2.mouthLoc[0] + scaledMouth1.shape[1]])\n",
    "            l8u_2 = frame2\n",
    "            r8u_2 = frame2_temp\n",
    "\n",
    "            l_2 = l8u_2.astype(np.float32) / 255.0\n",
    "            r_2 = r8u_2.astype(np.float32) / 255.0\n",
    "            m_2 = np.zeros(l_2.shape, dtype=np.float32)\n",
    "\n",
    "            mouthCenter2 = (d2.mouthLoc[0] + 0.5 * scaledMouth1.shape[1], d2.mouthLoc[1] + 0.5 * scaledMouth1.shape[0])\n",
    "            mouthAxis2 = (scaledMouth1.shape[1] * 0.5 - blend_range, scaledMouth1.shape[0] * 0.5 - blend_range)\n",
    "\n",
    "            cv2.ellipse(m_2, (int(mouthCenter2[0]), int(mouthCenter2[1])), (int(mouthAxis2[0]), int(mouthAxis2[1])), 0, 0, 360, 1, -1)\n",
    "            blend_2 = LaplacianBlend(l_2, r_2, m_2)\n",
    "\n",
    "            if DEBUG:\n",
    "                cv2.rectangle(blend_2, (d2.rectMouthCascade[0], d2.rectMouthCascade[1]), (d2.rectMouthCascade[0] + d2.rectMouthCascade[2], d2.rectMouthCascade[1] + d2.rectMouthCascade[3]), (0, 0, 255), 1)\n",
    "                cv2.rectangle(blend_2, (d2.rectMouth[0], d2.rectMouth[1]), (d2.rectMouth[0] + d2.rectMouth[2], d2.rectMouth[1] + d2.rectMouth[3]), (0, 255, 0), 1)\n",
    "\n",
    "            cv2.imshow(Window2, (blend_2 * 255).astype(np.uint8))\n",
    "\n",
    "        t = cv2.getTickCount() - t\n",
    "        print(f\"{t / (cv2.getTickFrequency() * 1000.0):.2f} ms\")\n",
    "\n",
    "    else:\n",
    "        cv2.imshow(Window2, frame2_temp)\n",
    "        cv2.imshow(Window1, frame1_temp)\n",
    "\n",
    "    key = cv2.waitKey(20) & 0xFF\n",
    "\n",
    "    if key == 27:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
